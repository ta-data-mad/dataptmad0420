{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 149.,\n",
       "       255., 184.,  12.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  11., 133., 212., 253., 253., 253., 102.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 162., 236., 253., 253.,\n",
       "       253., 253., 253.,  55.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        35., 196., 253., 253., 253., 253., 253., 253., 239.,  18.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  89., 249., 253., 253., 253., 185.,\n",
       "       253., 253., 177.,  24.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 129.,\n",
       "       247., 253., 253., 165., 150., 205., 253., 139.,   3.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  89., 247., 253., 240., 131.,  85., 221.,\n",
       "       253., 253.,  84.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   4., 187.,\n",
       "       253., 253., 236., 139., 252., 253., 253., 253.,  84.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  21., 253., 253., 253., 253., 253., 253.,\n",
       "       253., 253., 248.,  53.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  99.,\n",
       "       253., 253., 253., 253., 253., 214., 253., 253., 179.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   4., 186., 251., 253., 249., 172.,\n",
       "       133., 253., 253., 137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  49.,  94.,   6.,   0., 212., 253., 253.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       126., 253., 253., 197.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  27., 234., 253., 253.,  94.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       100., 253., 253., 239.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  61., 249., 253., 253.,  79.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,\n",
       "       109., 253., 253., 193.,   4.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  66., 253., 253., 253.,  30.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       147., 253., 253., 182.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  99., 248., 253., 222.,  13.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1798bacd10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = X[36000].reshape(28,28)\n",
    "plt.imshow(t, cmap = matplotlib.cm.binary, interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mnist['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dict = {'0': 0, '1': 0, '2':0, '3':0, '4': 0, '5': 1, '6':0, '7':0, '8': 0, '9': 0}\n",
    "l = []\n",
    "for i in a:\n",
    "    l.append(target_dict[i])\n",
    "target_5 = np.array(l)\n",
    "\n",
    "mnist['target_5'] = target_5\n",
    "\n",
    "\n",
    "X_5, y_5 = mnist['data'], mnist['target_5']\n",
    "\n",
    "X_5_train = X_5[:60000]\n",
    "y_5_train = y_5 [:60000]\n",
    "X_5_test = X_5[60000:]\n",
    "y_5_test = y_5[60000:]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IH_env]",
   "language": "python",
   "name": "conda-env-IH_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
