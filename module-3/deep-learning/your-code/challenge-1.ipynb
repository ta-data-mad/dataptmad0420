{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Tic Tac Toe\n",
    "\n",
    "In this lab you will perform deep learning analysis on a dataset of playing [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
    "\n",
    "There are 9 grids in Tic Tac Toe that are coded as the following picture shows:\n",
    "\n",
    "![Tic Tac Toe Grids](tttboard.jpg)\n",
    "\n",
    "In the first 9 columns of the dataset you can find which marks (`x` or `o`) exist in the grids. If there is no mark in a certain grid, it is labeled as `b`. The last column is `class` which tells you whether Player X (who always moves first in Tic Tac Toe) wins in this configuration. Note that when `class` has the value `False`, it means either Player O wins the game or it ends up as a draw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps suggested below to conduct a neural network analysis using Tensorflow and Keras. You will build a deep learning model to predict whether Player X wins the game or not.\n",
    "\n",
    "## Step 1: Data Engineering\n",
    "\n",
    "This dataset is almost in the ready-to-use state so you do not need to worry about missing values and so on. Still, some simple data engineering is needed.\n",
    "\n",
    "1. Read `tic-tac-toe.csv` into a dataframe.\n",
    "1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
    "1. Convert the categorical values to numeric in all columns.\n",
    "1. Separate the inputs and output.\n",
    "1. Normalize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958 entries, 0 to 957\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   TL      958 non-null    object\n",
      " 1   TM      958 non-null    object\n",
      " 2   TR      958 non-null    object\n",
      " 3   ML      958 non-null    object\n",
      " 4   MM      958 non-null    object\n",
      " 5   MR      958 non-null    object\n",
      " 6   BL      958 non-null    object\n",
      " 7   BM      958 non-null    object\n",
      " 8   BR      958 non-null    object\n",
      " 9   class   958 non-null    bool  \n",
      "dtypes: bool(1), object(9)\n",
      "memory usage: 68.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/juan/IronHack/dataptmad0420/module-3/deep-learning/your-code/tic-tac-toe.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TL TM TR ML MM MR BL BM BR  class\n",
       "0    x  x  x  x  o  o  x  o  o   True\n",
       "1    x  x  x  x  o  o  o  x  o   True\n",
       "2    x  x  x  x  o  o  o  o  x   True\n",
       "3    x  x  x  x  o  o  o  b  b   True\n",
       "4    x  x  x  x  o  o  b  o  b   True\n",
       "..  .. .. .. .. .. .. .. .. ..    ...\n",
       "953  o  x  x  x  o  o  o  x  x  False\n",
       "954  o  x  o  x  x  o  x  o  x  False\n",
       "955  o  x  o  x  o  x  x  o  x  False\n",
       "956  o  x  o  o  x  x  x  o  x  False\n",
       "957  o  o  x  x  x  o  o  x  x  False\n",
       "\n",
       "[958 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   19   20   21   22  \\\n",
       "0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  1.0  0.0  1.0   \n",
       "1  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  1.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  1.0  0.0  0.0  1.0   \n",
       "3  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  1.0  0.0  1.0  0.0   \n",
       "4  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "\n",
       "    23   24   25   26   27   28  \n",
       "0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
       "1  1.0  0.0  1.0  0.0  0.0  1.0  \n",
       "2  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "3  0.0  1.0  0.0  0.0  0.0  1.0  \n",
       "4  0.0  1.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_encoded.todense()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "cols = list(df.columns)\n",
    "\n",
    "\n",
    "le = LabelEncoder() \n",
    "\n",
    "for col in cols[:-1]:\n",
    "    df[col] = le.fit_transform(df[col]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TL  TM  TR  ML  MM  MR  BL  BM  BR  class\n",
       "0     2   2   2   2   1   1   2   1   1   True\n",
       "1     2   2   2   2   1   1   1   2   1   True\n",
       "2     2   2   2   2   1   1   1   1   2   True\n",
       "3     2   2   2   2   1   1   1   0   0   True\n",
       "4     2   2   2   2   1   1   0   1   0   True\n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
       "953   1   2   2   2   1   1   1   2   2  False\n",
       "954   1   2   1   2   2   1   2   1   2  False\n",
       "955   1   2   1   2   1   2   2   1   2  False\n",
       "956   1   2   1   1   2   2   2   1   2  False\n",
       "957   1   1   2   2   2   1   1   2   2  False\n",
       "\n",
       "[958 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TL  TM  TR  ML  MM  MR  BL  BM  BR  class\n",
       "0     2   2   2   2   1   1   2   1   1      1\n",
       "1     2   2   2   2   1   1   1   2   1      1\n",
       "2     2   2   2   2   1   1   1   1   2      1\n",
       "3     2   2   2   2   1   1   1   0   0      1\n",
       "4     2   2   2   2   1   1   0   1   0      1\n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
       "953   1   2   2   2   1   1   1   2   2      0\n",
       "954   1   2   1   2   2   1   2   1   2      0\n",
       "955   1   2   1   2   1   2   2   1   2      0\n",
       "956   1   2   1   1   2   2   2   1   2      0\n",
       "957   1   1   2   2   2   1   1   2   2      0\n",
       "\n",
       "[958 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoded_df = df.apply(encoder.fit_transform)\n",
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = encoded_df[['TL','TM','TR','ML','MM','MR','BL','BM','BR']]\n",
    "df_output = encoded_df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build Neural Network\n",
    "\n",
    "To build the neural network, you can refer to your own codes you wrote while following the [Deep Learning with Python, TensorFlow, and Keras tutorial](https://www.youtube.com/watch?v=wQ8BIBpya2k) in the lesson. It's pretty similar to what you will be doing in this lab.\n",
    "\n",
    "1. Split the training and test data.\n",
    "1. Create a `Sequential` model.\n",
    "1. Add several layers to your model. Make sure you use ReLU as the activation function for the middle layers. Use Softmax for the output layer because each output has a single lable and all the label probabilities add up to 1.\n",
    "1. Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
    "1. Fit the training data.\n",
    "1. Evaluate your neural network model with the test data.\n",
    "1. Save your model as `tic-tac-toe.model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(718,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_input_train, df_input_test, df_output_train, df_output_test = train_test_split(df_input, df_output)\n",
    "display(df_input_train.shape)\n",
    "display(df_output_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])\n",
    "df_input_train = pd.DataFrame(df_input_train)\n",
    "df_output_train = pd.DataFrame(df_output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6493 - accuracy: 0.6532 - val_loss: 0.6363 - val_accuracy: 0.6602\n",
      "Epoch 2/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6602 - val_loss: 0.6212 - val_accuracy: 0.6602\n",
      "Epoch 3/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6163 - accuracy: 0.6616 - val_loss: 0.6062 - val_accuracy: 0.6894\n",
      "Epoch 4/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6041 - accuracy: 0.7019 - val_loss: 0.5942 - val_accuracy: 0.7089\n",
      "Epoch 5/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.6992 - val_loss: 0.5823 - val_accuracy: 0.7298\n",
      "Epoch 6/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5796 - accuracy: 0.7354 - val_loss: 0.5708 - val_accuracy: 0.7423\n",
      "Epoch 7/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5683 - accuracy: 0.7521 - val_loss: 0.5600 - val_accuracy: 0.7563\n",
      "Epoch 8/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.7493 - val_loss: 0.5507 - val_accuracy: 0.7716\n",
      "Epoch 9/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7758 - val_loss: 0.5386 - val_accuracy: 0.7855\n",
      "Epoch 10/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7827 - val_loss: 0.5278 - val_accuracy: 0.7981\n",
      "Epoch 11/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.8022 - val_loss: 0.5290 - val_accuracy: 0.7772\n",
      "Epoch 12/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.8064 - val_loss: 0.5105 - val_accuracy: 0.8259\n",
      "Epoch 13/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.8189 - val_loss: 0.5000 - val_accuracy: 0.8357\n",
      "Epoch 14/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.8357 - val_loss: 0.4918 - val_accuracy: 0.8426\n",
      "Epoch 15/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.8357 - val_loss: 0.4849 - val_accuracy: 0.8468\n",
      "Epoch 16/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.8412 - val_loss: 0.4779 - val_accuracy: 0.8552\n",
      "Epoch 17/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.8524 - val_loss: 0.4714 - val_accuracy: 0.8663\n",
      "Epoch 18/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.8524 - val_loss: 0.4707 - val_accuracy: 0.8663\n",
      "Epoch 19/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.8538 - val_loss: 0.4704 - val_accuracy: 0.8496\n",
      "Epoch 20/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.8607 - val_loss: 0.4665 - val_accuracy: 0.8635\n",
      "Epoch 21/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.8579 - val_loss: 0.4574 - val_accuracy: 0.8733\n",
      "Epoch 22/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.8733 - val_loss: 0.4509 - val_accuracy: 0.9011\n",
      "Epoch 23/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.8830 - val_loss: 0.4492 - val_accuracy: 0.8942\n",
      "Epoch 24/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.8844 - val_loss: 0.4436 - val_accuracy: 0.8969\n",
      "Epoch 25/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.8955 - val_loss: 0.4432 - val_accuracy: 0.8983\n",
      "Epoch 26/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8900 - val_loss: 0.4342 - val_accuracy: 0.9081\n",
      "Epoch 27/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.9011 - val_loss: 0.4349 - val_accuracy: 0.8983\n",
      "Epoch 28/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.9123 - val_loss: 0.4277 - val_accuracy: 0.9123\n",
      "Epoch 29/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.9109 - val_loss: 0.4246 - val_accuracy: 0.9234\n",
      "Epoch 30/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.9067 - val_loss: 0.4215 - val_accuracy: 0.9234\n",
      "Epoch 31/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.9067 - val_loss: 0.4211 - val_accuracy: 0.9220\n",
      "Epoch 32/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.9136 - val_loss: 0.4162 - val_accuracy: 0.9290\n",
      "Epoch 33/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.9234 - val_loss: 0.4143 - val_accuracy: 0.9290\n",
      "Epoch 34/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.9206 - val_loss: 0.4108 - val_accuracy: 0.9276\n",
      "Epoch 35/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.9262 - val_loss: 0.4084 - val_accuracy: 0.9290\n",
      "Epoch 36/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.9248 - val_loss: 0.4063 - val_accuracy: 0.9345\n",
      "Epoch 37/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.9248 - val_loss: 0.4062 - val_accuracy: 0.9276\n",
      "Epoch 38/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.9276 - val_loss: 0.4024 - val_accuracy: 0.9387\n",
      "Epoch 39/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.9234 - val_loss: 0.4005 - val_accuracy: 0.9345\n",
      "Epoch 40/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.9276 - val_loss: 0.4016 - val_accuracy: 0.9304\n",
      "Epoch 41/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.9192 - val_loss: 0.3981 - val_accuracy: 0.9401\n",
      "Epoch 42/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.9331 - val_loss: 0.3966 - val_accuracy: 0.9373\n",
      "Epoch 43/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.9401 - val_loss: 0.3895 - val_accuracy: 0.9471\n",
      "Epoch 44/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.9401 - val_loss: 0.3903 - val_accuracy: 0.9513\n",
      "Epoch 45/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.9415 - val_loss: 0.3912 - val_accuracy: 0.9499\n",
      "Epoch 46/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.9457 - val_loss: 0.3846 - val_accuracy: 0.9526\n",
      "Epoch 47/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.9457 - val_loss: 0.3829 - val_accuracy: 0.9485\n",
      "Epoch 48/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.9485 - val_loss: 0.3803 - val_accuracy: 0.9513\n",
      "Epoch 49/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.9513 - val_loss: 0.3787 - val_accuracy: 0.9568\n",
      "Epoch 50/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.9443 - val_loss: 0.3774 - val_accuracy: 0.9554\n",
      "Epoch 51/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.9415 - val_loss: 0.3862 - val_accuracy: 0.9359\n",
      "Epoch 52/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.9415 - val_loss: 0.3777 - val_accuracy: 0.9513\n",
      "Epoch 53/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.9540 - val_loss: 0.3730 - val_accuracy: 0.9596\n",
      "Epoch 54/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.9526 - val_loss: 0.3722 - val_accuracy: 0.9610\n",
      "Epoch 55/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.9554 - val_loss: 0.3725 - val_accuracy: 0.9568\n",
      "Epoch 56/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.9457 - val_loss: 0.3728 - val_accuracy: 0.9638\n",
      "Epoch 57/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.9596 - val_loss: 0.3738 - val_accuracy: 0.9624\n",
      "Epoch 58/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.9652 - val_loss: 0.3681 - val_accuracy: 0.9680\n",
      "Epoch 59/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.9624 - val_loss: 0.3664 - val_accuracy: 0.9680\n",
      "Epoch 60/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.9610 - val_loss: 0.3655 - val_accuracy: 0.9652\n",
      "Epoch 61/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.9610 - val_loss: 0.3658 - val_accuracy: 0.9680\n",
      "Epoch 62/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.9652 - val_loss: 0.3624 - val_accuracy: 0.9708\n",
      "Epoch 63/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.9652 - val_loss: 0.3630 - val_accuracy: 0.9708\n",
      "Epoch 64/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.9680 - val_loss: 0.3603 - val_accuracy: 0.9708\n",
      "Epoch 65/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.9694 - val_loss: 0.3593 - val_accuracy: 0.9708\n",
      "Epoch 66/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.9694 - val_loss: 0.3595 - val_accuracy: 0.9680\n",
      "Epoch 67/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.9680 - val_loss: 0.3580 - val_accuracy: 0.9708\n",
      "Epoch 68/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.9694 - val_loss: 0.3587 - val_accuracy: 0.9680\n",
      "Epoch 69/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3601 - accuracy: 0.9680 - val_loss: 0.3563 - val_accuracy: 0.9708\n",
      "Epoch 70/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.9708 - val_loss: 0.3565 - val_accuracy: 0.9721\n",
      "Epoch 71/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.9708 - val_loss: 0.3554 - val_accuracy: 0.9721\n",
      "Epoch 72/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.9694 - val_loss: 0.3557 - val_accuracy: 0.9694\n",
      "Epoch 73/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.9708 - val_loss: 0.3538 - val_accuracy: 0.9708\n",
      "Epoch 74/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.9721 - val_loss: 0.3542 - val_accuracy: 0.9694\n",
      "Epoch 75/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.9708 - val_loss: 0.3533 - val_accuracy: 0.9721\n",
      "Epoch 76/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.9708 - val_loss: 0.3529 - val_accuracy: 0.9735\n",
      "Epoch 77/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.9694 - val_loss: 0.3527 - val_accuracy: 0.9721\n",
      "Epoch 78/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.9721 - val_loss: 0.3510 - val_accuracy: 0.9735\n",
      "Epoch 79/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.9721 - val_loss: 0.3503 - val_accuracy: 0.9735\n",
      "Epoch 80/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.9721 - val_loss: 0.3503 - val_accuracy: 0.9735\n",
      "Epoch 81/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.9708 - val_loss: 0.3499 - val_accuracy: 0.9735\n",
      "Epoch 82/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.9708 - val_loss: 0.3513 - val_accuracy: 0.9708\n",
      "Epoch 83/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.9708 - val_loss: 0.3496 - val_accuracy: 0.9735\n",
      "Epoch 84/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.9735 - val_loss: 0.3483 - val_accuracy: 0.9735\n",
      "Epoch 85/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.9735 - val_loss: 0.3484 - val_accuracy: 0.9735\n",
      "Epoch 86/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.9749 - val_loss: 0.3493 - val_accuracy: 0.9694\n",
      "Epoch 87/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.9721 - val_loss: 0.3461 - val_accuracy: 0.9749\n",
      "Epoch 88/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.9763 - val_loss: 0.3462 - val_accuracy: 0.9763\n",
      "Epoch 89/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.9749 - val_loss: 0.3458 - val_accuracy: 0.9763\n",
      "Epoch 90/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.9749 - val_loss: 0.3449 - val_accuracy: 0.9763\n",
      "Epoch 91/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.9763 - val_loss: 0.3456 - val_accuracy: 0.9777\n",
      "Epoch 92/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.9777 - val_loss: 0.3434 - val_accuracy: 0.9777\n",
      "Epoch 93/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.9777 - val_loss: 0.3430 - val_accuracy: 0.9791\n",
      "Epoch 94/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.9777 - val_loss: 0.3424 - val_accuracy: 0.9791\n",
      "Epoch 95/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.9791 - val_loss: 0.3422 - val_accuracy: 0.9791\n",
      "Epoch 96/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.9777 - val_loss: 0.3420 - val_accuracy: 0.9791\n",
      "Epoch 97/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.9777 - val_loss: 0.3454 - val_accuracy: 0.9791\n",
      "Epoch 98/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.9791 - val_loss: 0.3416 - val_accuracy: 0.9791\n",
      "Epoch 99/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.9777 - val_loss: 0.3427 - val_accuracy: 0.9791\n",
      "Epoch 100/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.9791 - val_loss: 0.3409 - val_accuracy: 0.9791\n",
      "Epoch 101/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.9791 - val_loss: 0.3403 - val_accuracy: 0.9791\n",
      "Epoch 102/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.9791 - val_loss: 0.3401 - val_accuracy: 0.9791\n",
      "Epoch 103/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.9791 - val_loss: 0.3398 - val_accuracy: 0.9791\n",
      "Epoch 104/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.9791 - val_loss: 0.3398 - val_accuracy: 0.9791\n",
      "Epoch 105/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.9791 - val_loss: 0.3403 - val_accuracy: 0.9805\n",
      "Epoch 106/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.9805 - val_loss: 0.3391 - val_accuracy: 0.9805\n",
      "Epoch 107/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.9805 - val_loss: 0.3388 - val_accuracy: 0.9805\n",
      "Epoch 108/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.9805 - val_loss: 0.3385 - val_accuracy: 0.9791\n",
      "Epoch 109/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.9805 - val_loss: 0.3407 - val_accuracy: 0.9791\n",
      "Epoch 110/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.9819 - val_loss: 0.3388 - val_accuracy: 0.9805\n",
      "Epoch 111/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.9805 - val_loss: 0.3418 - val_accuracy: 0.9777\n",
      "Epoch 112/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.9819 - val_loss: 0.3396 - val_accuracy: 0.9805\n",
      "Epoch 113/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.9819 - val_loss: 0.3372 - val_accuracy: 0.9833\n",
      "Epoch 114/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.9833 - val_loss: 0.3363 - val_accuracy: 0.9833\n",
      "Epoch 115/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.9833 - val_loss: 0.3351 - val_accuracy: 0.9833\n",
      "Epoch 116/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.9847 - val_loss: 0.3352 - val_accuracy: 0.9861\n",
      "Epoch 117/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.9847 - val_loss: 0.3338 - val_accuracy: 0.9861\n",
      "Epoch 118/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.9861 - val_loss: 0.3328 - val_accuracy: 0.9861\n",
      "Epoch 119/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.9861 - val_loss: 0.3325 - val_accuracy: 0.9861\n",
      "Epoch 120/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.9861 - val_loss: 0.3335 - val_accuracy: 0.9861\n",
      "Epoch 121/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.9861 - val_loss: 0.3322 - val_accuracy: 0.9861\n",
      "Epoch 122/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.9861 - val_loss: 0.3319 - val_accuracy: 0.9861\n",
      "Epoch 123/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.9861 - val_loss: 0.3316 - val_accuracy: 0.9861\n",
      "Epoch 124/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.9861 - val_loss: 0.3316 - val_accuracy: 0.9861\n",
      "Epoch 125/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.9861 - val_loss: 0.3313 - val_accuracy: 0.9861\n",
      "Epoch 126/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.9861 - val_loss: 0.3313 - val_accuracy: 0.9861\n",
      "Epoch 127/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.9861 - val_loss: 0.3313 - val_accuracy: 0.9861\n",
      "Epoch 128/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.9861 - val_loss: 0.3316 - val_accuracy: 0.9861\n",
      "Epoch 129/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.9861 - val_loss: 0.3310 - val_accuracy: 0.9861\n",
      "Epoch 130/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.9861 - val_loss: 0.3319 - val_accuracy: 0.9861\n",
      "Epoch 131/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.9875 - val_loss: 0.3295 - val_accuracy: 0.9875\n",
      "Epoch 132/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.9875 - val_loss: 0.3293 - val_accuracy: 0.9875\n",
      "Epoch 133/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.9875 - val_loss: 0.3287 - val_accuracy: 0.9889\n",
      "Epoch 134/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.9875 - val_loss: 0.3293 - val_accuracy: 0.9889\n",
      "Epoch 135/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.9889 - val_loss: 0.3287 - val_accuracy: 0.9889\n",
      "Epoch 136/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.9889 - val_loss: 0.3284 - val_accuracy: 0.9889\n",
      "Epoch 137/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.9889 - val_loss: 0.3280 - val_accuracy: 0.9889\n",
      "Epoch 138/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.9889 - val_loss: 0.3280 - val_accuracy: 0.9889\n",
      "Epoch 139/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.9889 - val_loss: 0.3280 - val_accuracy: 0.9889\n",
      "Epoch 140/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.9889 - val_loss: 0.3275 - val_accuracy: 0.9889\n",
      "Epoch 141/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.9889 - val_loss: 0.3281 - val_accuracy: 0.9889\n",
      "Epoch 142/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.9889 - val_loss: 0.3273 - val_accuracy: 0.9889\n",
      "Epoch 143/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.9889 - val_loss: 0.3273 - val_accuracy: 0.9889\n",
      "Epoch 144/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.9889 - val_loss: 0.3274 - val_accuracy: 0.9889\n",
      "Epoch 145/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.9889 - val_loss: 0.3275 - val_accuracy: 0.9889\n",
      "Epoch 146/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3274 - accuracy: 0.9889 - val_loss: 0.3271 - val_accuracy: 0.9889\n",
      "Epoch 147/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.9889 - val_loss: 0.3271 - val_accuracy: 0.9889\n",
      "Epoch 148/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.9889 - val_loss: 0.3269 - val_accuracy: 0.9889\n",
      "Epoch 149/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.9889 - val_loss: 0.3270 - val_accuracy: 0.9889\n",
      "Epoch 150/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.9889 - val_loss: 0.3268 - val_accuracy: 0.9889\n",
      "Epoch 151/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.9889 - val_loss: 0.3268 - val_accuracy: 0.9889\n",
      "Epoch 152/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.9889 - val_loss: 0.3268 - val_accuracy: 0.9889\n",
      "Epoch 153/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.9889 - val_loss: 0.3277 - val_accuracy: 0.9889\n",
      "Epoch 154/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.9889 - val_loss: 0.3269 - val_accuracy: 0.9889\n",
      "Epoch 155/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.9889 - val_loss: 0.3276 - val_accuracy: 0.9889\n",
      "Epoch 156/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.9889 - val_loss: 0.3265 - val_accuracy: 0.9889\n",
      "Epoch 157/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.9889 - val_loss: 0.3265 - val_accuracy: 0.9889\n",
      "Epoch 158/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.9889 - val_loss: 0.3264 - val_accuracy: 0.9889\n",
      "Epoch 159/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.9889 - val_loss: 0.3263 - val_accuracy: 0.9889\n",
      "Epoch 160/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.9889 - val_loss: 0.3262 - val_accuracy: 0.9889\n",
      "Epoch 161/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.9889 - val_loss: 0.3263 - val_accuracy: 0.9889\n",
      "Epoch 162/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.9889 - val_loss: 0.3263 - val_accuracy: 0.9889\n",
      "Epoch 163/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.9889 - val_loss: 0.3262 - val_accuracy: 0.9889\n",
      "Epoch 164/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.9889 - val_loss: 0.3261 - val_accuracy: 0.9889\n",
      "Epoch 165/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.9889 - val_loss: 0.3262 - val_accuracy: 0.9889\n",
      "Epoch 166/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.9889 - val_loss: 0.3261 - val_accuracy: 0.9889\n",
      "Epoch 167/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.9889 - val_loss: 0.3260 - val_accuracy: 0.9889\n",
      "Epoch 168/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.9889 - val_loss: 0.3261 - val_accuracy: 0.9889\n",
      "Epoch 169/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.9889 - val_loss: 0.3259 - val_accuracy: 0.9889\n",
      "Epoch 170/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.9889 - val_loss: 0.3259 - val_accuracy: 0.9889\n",
      "Epoch 171/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.9889 - val_loss: 0.3259 - val_accuracy: 0.9889\n",
      "Epoch 172/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.9889 - val_loss: 0.3259 - val_accuracy: 0.9889\n",
      "Epoch 173/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.9889 - val_loss: 0.3258 - val_accuracy: 0.9889\n",
      "Epoch 174/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.9889 - val_loss: 0.3261 - val_accuracy: 0.9889\n",
      "Epoch 175/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.9889 - val_loss: 0.3258 - val_accuracy: 0.9889\n",
      "Epoch 176/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.9889 - val_loss: 0.3260 - val_accuracy: 0.9889\n",
      "Epoch 177/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.9889 - val_loss: 0.3257 - val_accuracy: 0.9889\n",
      "Epoch 178/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.9889 - val_loss: 0.3259 - val_accuracy: 0.9889\n",
      "Epoch 179/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.9889 - val_loss: 0.3257 - val_accuracy: 0.9889\n",
      "Epoch 180/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.9889 - val_loss: 0.3257 - val_accuracy: 0.9889\n",
      "Epoch 181/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.9889 - val_loss: 0.3257 - val_accuracy: 0.9889\n",
      "Epoch 182/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.9889 - val_loss: 0.3256 - val_accuracy: 0.9889\n",
      "Epoch 183/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.9889 - val_loss: 0.3256 - val_accuracy: 0.9889\n",
      "Epoch 184/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.9889 - val_loss: 0.3256 - val_accuracy: 0.9889\n",
      "Epoch 185/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.9889 - val_loss: 0.3256 - val_accuracy: 0.9889\n",
      "Epoch 186/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.9889 - val_loss: 0.3256 - val_accuracy: 0.9889\n",
      "Epoch 187/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.9889 - val_loss: 0.3255 - val_accuracy: 0.9889\n",
      "Epoch 188/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.9889 - val_loss: 0.3255 - val_accuracy: 0.9889\n",
      "Epoch 189/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.9889 - val_loss: 0.3255 - val_accuracy: 0.9889\n",
      "Epoch 190/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.9889 - val_loss: 0.3255 - val_accuracy: 0.9889\n",
      "Epoch 191/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.9889 - val_loss: 0.3255 - val_accuracy: 0.9889\n",
      "Epoch 192/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.9889 - val_loss: 0.3254 - val_accuracy: 0.9889\n",
      "Epoch 193/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.9889 - val_loss: 0.3254 - val_accuracy: 0.9889\n",
      "Epoch 194/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.9889 - val_loss: 0.3254 - val_accuracy: 0.9889\n",
      "Epoch 195/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9889 - val_loss: 0.3254 - val_accuracy: 0.9889\n",
      "Epoch 196/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9889 - val_loss: 0.3254 - val_accuracy: 0.9889\n",
      "Epoch 197/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9889 - val_loss: 0.3254 - val_accuracy: 0.9889\n",
      "Epoch 198/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9889 - val_loss: 0.3254 - val_accuracy: 0.9889\n",
      "Epoch 199/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9889 - val_loss: 0.3254 - val_accuracy: 0.9889\n",
      "Epoch 200/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 201/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 202/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 203/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 204/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 205/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 206/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 207/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 208/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 209/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3252 - val_accuracy: 0.9889\n",
      "Epoch 210/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3253 - val_accuracy: 0.9889\n",
      "Epoch 211/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.9889 - val_loss: 0.3252 - val_accuracy: 0.9889\n",
      "Epoch 212/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.9889 - val_loss: 0.3252 - val_accuracy: 0.9889\n",
      "Epoch 213/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.9889 - val_loss: 0.3252 - val_accuracy: 0.9889\n",
      "Epoch 214/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.9889 - val_loss: 0.3250 - val_accuracy: 0.9889\n",
      "Epoch 215/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.9889 - val_loss: 0.3249 - val_accuracy: 0.9889\n",
      "Epoch 216/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.9889 - val_loss: 0.3244 - val_accuracy: 0.9903\n",
      "Epoch 217/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.9903 - val_loss: 0.3241 - val_accuracy: 0.9903\n",
      "Epoch 218/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.9903 - val_loss: 0.3242 - val_accuracy: 0.9903\n",
      "Epoch 219/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.9903 - val_loss: 0.3239 - val_accuracy: 0.9903\n",
      "Epoch 220/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.9903 - val_loss: 0.3239 - val_accuracy: 0.9903\n",
      "Epoch 221/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.9903 - val_loss: 0.3238 - val_accuracy: 0.9903\n",
      "Epoch 222/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.9903 - val_loss: 0.3238 - val_accuracy: 0.9903\n",
      "Epoch 223/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.9903 - val_loss: 0.3239 - val_accuracy: 0.9903\n",
      "Epoch 224/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.9903 - val_loss: 0.3238 - val_accuracy: 0.9903\n",
      "Epoch 225/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.9903 - val_loss: 0.3238 - val_accuracy: 0.9903\n",
      "Epoch 226/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.9903 - val_loss: 0.3238 - val_accuracy: 0.9903\n",
      "Epoch 227/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.9903 - val_loss: 0.3238 - val_accuracy: 0.9903\n",
      "Epoch 228/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.9903 - val_loss: 0.3237 - val_accuracy: 0.9903\n",
      "Epoch 229/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.9903 - val_loss: 0.3238 - val_accuracy: 0.9903\n",
      "Epoch 230/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.9903 - val_loss: 0.3237 - val_accuracy: 0.9903\n",
      "Epoch 231/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.9903 - val_loss: 0.3237 - val_accuracy: 0.9903\n",
      "Epoch 232/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.9903 - val_loss: 0.3237 - val_accuracy: 0.9903\n",
      "Epoch 233/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.9903 - val_loss: 0.3237 - val_accuracy: 0.9903\n",
      "Epoch 234/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.9903 - val_loss: 0.3237 - val_accuracy: 0.9903\n",
      "Epoch 235/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.9903 - val_loss: 0.3237 - val_accuracy: 0.9903\n",
      "Epoch 236/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 237/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.9903 - val_loss: 0.3237 - val_accuracy: 0.9903\n",
      "Epoch 238/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 239/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 240/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 241/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 242/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 243/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 244/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 245/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 246/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 247/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 248/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3236 - val_accuracy: 0.9903\n",
      "Epoch 249/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 250/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 251/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 252/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 253/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 254/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 255/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 256/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 257/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 258/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 259/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 260/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 261/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 262/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 263/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 264/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 265/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3235 - val_accuracy: 0.9903\n",
      "Epoch 266/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 267/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 268/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 269/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 270/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 271/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 272/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 273/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 274/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 275/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 276/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 277/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 278/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 279/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 280/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 281/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 282/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 283/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 284/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 285/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 286/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 287/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 288/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 289/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 290/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 291/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3234 - val_accuracy: 0.9903\n",
      "Epoch 292/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 293/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 294/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 295/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 296/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 297/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 298/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 299/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 300/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 301/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 302/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 303/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 304/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 305/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 306/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 307/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 308/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 309/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 310/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 311/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 312/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 313/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 314/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 315/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 316/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 317/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3233 - val_accuracy: 0.9903\n",
      "Epoch 318/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 319/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 320/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3233 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 321/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 322/400\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 323/400\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 324/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 325/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 326/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 327/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 328/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 329/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 330/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 331/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 332/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 333/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 334/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 335/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 336/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 337/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 338/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 339/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 340/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 341/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 342/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 343/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 344/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 345/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 346/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 347/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 348/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 349/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 350/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 351/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 352/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 353/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 354/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 355/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 356/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 357/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 358/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 359/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 360/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 361/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 362/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 363/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 364/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 365/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 366/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 367/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 368/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 369/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 370/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 371/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 372/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 373/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 374/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 375/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3232 - val_accuracy: 0.9903\n",
      "Epoch 376/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 377/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 378/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 379/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 380/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 381/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 382/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 383/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 384/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 385/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 386/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 387/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 388/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 389/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 390/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 391/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 392/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 393/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 394/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 395/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 396/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 397/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 398/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 399/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n",
      "Epoch 400/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.9903 - val_loss: 0.3231 - val_accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "mod = model.fit(df_input_train, df_output_train, epochs=400, batch_size=64, validation_data=(df_input_train, df_output_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 668us/step - loss: 0.3231 - accuracy: 0.9903\n",
      "0.3231230080127716 0.9902507066726685\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(df_input_train, df_output_train)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tic-tac-toe.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('tic-tac-toe.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions\n",
    "\n",
    "Now load your saved model and use it to make predictions on a few random rows in the test dataset. Check if the predictions are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "new_model = tf.keras.models.load_model('tic-tac-toe.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(df_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#print(predictions)\n",
    "import numpy as np\n",
    "print(np.argmax(predictions[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.9125\n",
      "0.3998965322971344 0.9125000238418579\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(df_input_test, df_output_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improve Your Model\n",
    "\n",
    "Did your model achieve low loss (<0.1) and high accuracy (>0.95)? If not, try to improve your model.\n",
    "\n",
    "But how? There are so many things you can play with in Tensorflow and in the next challenge you'll learn about these things. But in this challenge, let's just do a few things to see if they will help.\n",
    "\n",
    "* Add more layers to your model. If the data are complex you need more layers. But don't use more layers than you need. If adding more layers does not improve the model performance you don't need additional layers.\n",
    "* Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want. Then pass the instance to `model.compile` as the optimizer.\n",
    "    * `tf.keras.optimizers.Adam` [reference](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
    "    * Don't worry if you don't understand what the learning rate does. You'll learn about it in the next challenge.\n",
    "* Adjust the number of epochs when you fit the training data to the model. Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7f76cc0d9110>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which approach(es) did you find helpful to improve your model performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "'''\n",
    "The most helpful thing to improve my model has been increase the number of epochs\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ironhack]",
   "language": "python",
   "name": "conda-env-ironhack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
